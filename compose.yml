version: '3'

services:
  duckdb:
    container_name: duckdb
    image: python:3.12.7-slim-bookworm
    build:
      context: ./duckdb
    volumes:
      - ../mnt/tmp/duckdb_data:/app/data
    stdin_open: true
    tty: true
    environment:
      PYICEBERG_HOME: /app/data   #VIST LEIAB SIIT .pyiceberg.yaml-i
    networks:
      iceberg_network:
  minio:
    image: minio/minio:RELEASE.2024-10-13T13-34-11Z
    container_name: minio
    ports:
      - "9000:9000"   # MinIO API port
      - "9001:9001"   # MinIO Console port
    environment:
      MINIO_ROOT_USER: minioadmin      
      MINIO_ROOT_PASSWORD: minioadmin  
      MINIO_DOMAIN: minio
    command: server /data --console-address ":9001"
    volumes:
      - ../mnt/tmp/minio_data:/data
    networks:
      iceberg_network:
        aliases:
          - warehouse.minio
  iceberg_rest:
    image: tabulario/iceberg-rest:1.6.0
    container_name: iceberg_rest
    ports:
      - "8181:8181" 
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
      CATALOG_WAREHOUSE: s3://warehouse/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9000 
    depends_on:
      - minio
    networks:
      iceberg_network:
  mc:
    depends_on:
      - minio
    image: minio/mc:RELEASE.2024-10-02T08-27-28Z
    container_name: mc
    networks:
      iceberg_network:
    entrypoint: >
        /bin/sh -c "
        until (/usr/bin/mc config host add minio http://minio:9000 minioadmin minioadmin) do echo '...waiting...' && sleep 1; done;
        /usr/bin/mc rm -r --force minio/warehouse;
        /usr/bin/mc mb minio/warehouse;
        /usr/bin/mc policy set public minio/warehouse;
        "
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    networks:
      - iceberg_network

  airflow-webserver:
    build:
      context: ./airflow
    container_name: airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY='iUXMxHcly_9XJHn3kljmoyvF4IxVL6Vgd5eK5yHld9w='
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_ENDPOINT=minio:9000
      - PYICEBERG_CATALOG__REST__URI=http://iceberg_rest:8181
      - PYICEBERG_CATALOG__REST__WAREHOUSE=s3://warehouse         #NEED ASJAD ON KA duckdb/.pyiceberg.yaml-is NII ET PEAKS KATSETAMA, KAS VÕIB SIIT ÄRA VÕTTA
      - PYICEBERG_CATALOG__REST__S3__ENDPOINT=http://minio:9000
      - PYICEBERG_CATALOG__REST__S3__ACCESS_KEY_ID=minioadmin
      - PYICEBERG_CATALOG__REST__S3__SECRET_ACCESS_KEY=minioadmin
      - PYICEBERG_CATALOG__REST__S3__PATH_STYLE_ACCESS=true
      - AIRFLOW__WEBSERVER__SECRET_KEY='a-very-long-secret-key-that-you-should-change-123456789'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./mnt/tmp/duckdb_data:/app/data
      - ./data:/opt/airflow/data
      - .:/opt/airflow/project_data
    ports:
      - "8080:8080"
    depends_on:
      - postgres
      - minio
      - iceberg_rest
    restart: always
    command: webserver
    networks:
      - iceberg_network

  airflow-scheduler:
    build:
      context: ./airflow
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY='iUXMxHcly_9XJHn3kljmoyvF4IxVL6Vgd5eK5yHld9w='
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_ENDPOINT=minio:9000
      - PYICEBERG_CATALOG__REST__URI=http://iceberg_rest:8181
      - PYICEBERG_CATALOG__REST__WAREHOUSE=s3://warehouse
      - PYICEBERG_CATALOG__REST__S3__ENDPOINT=http://minio:9000
      - PYICEBERG_CATALOG__REST__S3__ACCESS_KEY_ID=minioadmin
      - PYICEBERG_CATALOG__REST__S3__SECRET_ACCESS_KEY=minioadmin
      - PYICEBERG_CATALOG__REST__S3__PATH_STYLE_ACCESS=true
      - AIRFLOW__WEBSERVER__SECRET_KEY='a-very-long-secret-key-that-you-should-change-123456789'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./mnt/tmp/duckdb_data:/app/data
      - ./data:/opt/airflow/data
      - .:/opt/airflow/project_data
    depends_on:
      - postgres
      - minio
      - iceberg_rest
    restart: always
    command: scheduler
    user: root
    networks:
      - iceberg_network

  airflow-init:
    image: apache/airflow:2.7.1
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY='iUXMxHcly_9XJHn3kljmoyvF4IxVL6Vgd5eK5yHld9w='
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY='a-very-long-secret-key-that-you-should-change-123456789'
    volumes:
      - ./mnt/tmp/duckdb_data:/app/data
      - .:/opt/airflow/project_data
    entrypoint: "airflow db init"
    networks:
      - iceberg_network

networks:
  iceberg_network:
    driver: bridge

volumes:
  postgres-db-volume: